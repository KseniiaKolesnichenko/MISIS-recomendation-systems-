# -*- coding: utf-8 -*-
"""RNN_test_for_future_errors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I4zKvZe7223Gq4fBUeix09vPqInjab4m
"""

!pip install --upgrade numpy

from google.colab import drive
drive.mount('/content/drive')

file='8302_ver1.xlsx'

"""# Загрузка и предобработка данных"""

# Commented out IPython magic to ensure Python compatibility.
import torch
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
from torch.nn import RNN, LSTM
import torch.nn.functional as F

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

torch.cuda.is_available()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #Загрузка данных
# 
# directory='drive/MyDrive/Colab Notebooks/Drilling_error_prediction/'
# raw_df=pd.read_excel(directory+'Data/'+file)

raw_df.replace(-999.25, np.nan, inplace=True)

#Исправление частых опечаток
raw_df.rename(columns={'Мес корость ср': 'Мех. скорость ср',
    'Мех корость ср': 'Мех. скорость ср',
    'Мех скорость ср': 'Мех. скорость ср',
    'Мех ск. средняя': 'Мех. скорость ср',
    'ЦСГО':'ЦСГО 1',
    'ЦСГО ':'ЦСГО 1',
    'Суммарная емкость': 'Сумма актив. емкостей',
                       'Сумманная емкость': 'Сумма актив. емкостей',
                       'Сумманая емкость': 'Сумма актив. емкостей',
                       'Сумма актив. ёмкостей': 'Сумма актив. емкостей',
                       'Сумма актив. ёмк.': 'Сумма актив. емкостей',
                       'Сумм. актив ёмк.': 'Сумма актив. емкостей',
                       'Сумма актив ёмк': 'Сумма актив. емкостей',
                      'Рабочаяемк. 1': 'Рабочая емк. 1',
                      'Рабочая емк.1': 'Рабочая емк. 1',
                      'Ёмк1': 'Рабочая емк. 1', 'Ёмк 1': 'Рабочая емк. 1',
                       'Рабочая ёмкость ': 'Рабочая емк. 1',
                      'Рабочаяемк. 2': 'Рабочая емк. 2',
                      'Рабочая емк.2': 'Рабочая емк. 2',
                       'Ёмк2': 'Рабочая емк. 2', 'Ёмк 2': 'Рабочая емк. 2',
                       'Рабочая ёмкость 2': 'Рабочая емк. 2',
                      'Код литологии': 'Код Литологии',
                      'код стратиграфии': 'Код стратиграфии',
                       'код горизонта маркера': 'Код горизонта маркера',
                       'Код горизонта макрера': 'Код горизонта маркера',
                      'Диаметр долота ': 'Диаметр долота',
                       'Температура вход':'Температура вх',
                       'Долив 1':'Долив',
                       'Расход вход': 'Расход на вх', 'Поток вых':'Расход на вых.',
                       'Расход ны вых.':'Расход на вых.',
                       'Вес на крюке': 'Вес на кр',
                       'Нагр на дол': 'Нагр. На долото',
                       'Обороты': 'Обороты рот',
                       'Высота крюка': 'Положение кр',
                       'Глубина долота': 'Положение долота',
                       'Плотность вход': 'Плотность на вх', 
                       'Плотность вых': 'Плотность на вых',
                      'C1':'С1', 'C2':'С2','C3':'С3','C4':'С4', 'C5':'C5',
                      'iC4':'iС4', 'iC5':'IC5', 'nC4':'С4', 'nC5':'C5',
                       'PITVOL_1':'Рабочая емк. 1', 'PITVOL_2':'Рабочая емк. 2',
                       'PITVOL_9':'Сумма актив. емкостей', 'PITVOL_3':'БПР 1',
                       'PITVOL_4':'БПР 2', 'PITVOL_5':'ЦСГО 1', 'PITVOL_6':'ЦСГО 2',
                       'PITVOL_7':'Долив','PITVOL_8':'Долив 2'
                      }, inplace=True)

raw_df.drop(index=0, inplace=True)
raw_df['Код осложнений'].fillna(value=0, inplace=True)

raw_df.head()

rows_with_NA=raw_df.isna().any(axis=1).sum()
print(f'Number of NaN values: {rows_with_NA},\
part of NaN values: {rows_with_NA/len(raw_df)*100:.2f} %\n')

"""# Загрузка модели"""

#рекурентная сеть
class GRU_encoder(nn.Module):
    def __init__(self, input_size, hidden_dim, output_size, num_layers=1):
        super().__init__()

        self.rnn = nn.GRU(input_size, hidden_size = hidden_dim, num_layers = num_layers, batch_first=True)
        #self.fc = nn.Linear(hidden_dim, output_size)
        self.out_size=output_size
    
    def forward(self, x):
        batch_size = x.size(0)
        #print(x.size())
        #Инициализация скрытого состояния
        hidden_0 = torch.zeros((self.rnn.num_layers, batch_size, self.rnn.hidden_size), device=device) 
        #cell_0 = torch.zeros((self.lstm.num_layers, batch_size, self.lstm.hidden_size), device=device)
        #print(hidden_0.size())
        # Слой LSTM
        
        rnn_out, hidden = self.rnn(x, hidden_0)
         
        #print(hidden.size())
        #Полносвязный слой
        #out = out.contiguous().view(-1, self.rnn.hidden_size)
        #out = hidden[0][-1]
        #out = F.relu(self.fc_intermediate(out))
        #out = self.fc(out)
        return rnn_out, hidden
        #return out.view(-1, self.out_size), out

class GRU_decoder(nn.Module):
    def __init__(self, input_size, hidden_dim, n_classes, n_steps_forward):
      super().__init__()

      self.rnn_cell = nn.GRUCell(input_size, hidden_size = hidden_dim)
      self.fc= nn.Linear(hidden_dim, n_classes)
      self.n_steps=n_steps_forward

    def forward(self,x, encoder_hidden_state):

      current_hidden_state=encoder_hidden_state
      #print(encoder_hidden_state.shape)
      hiddens=[]
      outs=[]
      for _ in range(self.n_steps):
        hidden = self.rnn_cell(x, current_hidden_state)
        hiddens.append(hidden)
        out=self.fc(hidden)
        outs.append(out)
      return outs, hiddens 

class GRU_seq2seq(nn.Module):
    def __init__(self, encoder, decoder, output_size):
      super().__init__()

      self.encoder=encoder
      self.decoder=decoder
      self.out_size=output_size

    def forward(self,x):
      _,encoder_hidden=self.encoder.forward(x)
      
      #print(encoder_hidden.shape)
      outputs,_=self.decoder.forward(x[:,-1],encoder_hidden[0])
      return outputs

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model_file='torch.Size([666350, 50, 41])samples_accuracy_0.75598_future_pred'
model=torch.load(directory+"Code/trained_models/"+model_file+".pth",map_location=device)
model

order=pd.read_csv(directory+'Code/trained_models/'+model_file+'_Order_of_columns.csv', header=None)

print('Columns order:')
print(order[0])

df=raw_df[order[0]]

rows_with_NA=df.isna().any(axis=1).sum()
print(f'Number of NaN values in cut data: {rows_with_NA},\
part of NaN values: {rows_with_NA/len(df)*100:.2f} %\n')

df.dropna(inplace=True)

df=df.astype(np.float32, copy=False) 
df=df.astype({'Код Литологии': np.uint16,'Код осложнений': np.uint16, 'Код стратиграфии': np.uint16}
                                     , copy=False)

df.info()

#Масштабы
scales=pd.read_excel(directory+'Data/Масштабы.xlsx')

for column in df.columns:
    if not scales[column].isnull().all():
        max_value = scales[column].loc[2]
        min_value = scales[column].loc[1]
        df[column] = (df[column] - min_value) / (max_value - min_value)

min_depth=scales['Глубина'].loc[1]
max_depth=scales['Глубина'].loc[2]

df.head()

"""# Формирование датасета из данных"""

from sklearn.preprocessing import OneHotEncoder, LabelEncoder

#Коды литологии и стратиграфии
litology_code=pd.read_csv(directory+'Data/Литология_коды.csv', header=1, delimiter=';', usecols=[0,1])
stratigraphy_code=pd.read_csv(directory+'Data/Стратиграфия_коды.csv', header=1, delimiter=';', usecols=[0,1])

#В файлах встречаются коды литологии 12, 16, 113
#Встречаются стратиграфии 30
lit_codes=np.sort(np.hstack([litology_code['Код литологии'].values,12,16,113, 64537]))
print(f"Количество литологий: {len(lit_codes)}")
strat_codes=np.sort(np.hstack([stratigraphy_code['Код стратиграфии'].values])).reshape(1,-1)
print(f"Количество стратиграфий: {len(strat_codes[0])}")

encoder_lit = OneHotEncoder(categories=lit_codes.reshape(1,-1))
encoder_strat = OneHotEncoder(categories=strat_codes)
label_encoder=LabelEncoder()

#Если нужно, то заменяем некоторые коды литологии и стратиграфии
df.replace({"Код стратиграфии": {30: 31}}, inplace=True)

# Commented out IPython magic to ensure Python compatibility.
# %%capture --no-stdout
# #Перевод всех данных в двумерный массив и one-hot encoding для столбцов 
# #кодов литологии и кодов стратиграфии
# 
# X=df.drop(columns=['Код Литологии', 'Код осложнений', 'Код стратиграфии']).values
# #Y=df['Код осложнений'].values
# Y=(df['Код осложнений'].values>0).astype(int)
# encoded_X_lit=encoder_lit.fit_transform(df['Код Литологии'].values.reshape(-1,1)).toarray()
# encoded_X_strat=encoder_strat.fit_transform(df['Код стратиграфии'].values.reshape(-1,1)).toarray()
# #total_X= np.hstack([X, encoded_X_lit, encoded_X_strat])
# total_X=np.hstack([X, encoded_X_strat])
# total_Y=Y

total_X.shape

# Commented out IPython magic to ensure Python compatibility.
# %%capture --no-stdout
# #Объединение данных в группы по number_of_depth_points точек
# number_of_depth_points=50
# n_steps_forward=10
#     
# X_grouped=np.lib.stride_tricks.sliding_window_view(total_X,(number_of_depth_points,total_X.shape[1]))[:-n_steps_forward,0]
#     
# Y_grouped=np.lib.stride_tricks.sliding_window_view(Y[number_of_depth_points:],(n_steps_forward,))
# 
# print(X_grouped.shape)
# print(Y_grouped.shape)

"""# Тест модели"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# outputs = model(torch.Tensor(X_grouped))

n_outputs = model.decoder.n_steps
correct_answers = np.zeros(n_outputs)
correctly_predicted_errors = np.zeros(n_outputs)
total_samples=np.zeros(n_outputs)
total_errors=np.zeros(n_outputs)
    
with torch.no_grad():
    labels = torch.Tensor(Y_grouped)
    for ind, output in enumerate(outputs):
      label=labels[:,ind]
      _, predicted = torch.max(output.data, 1)
      #print(labels>0)
      correct_answers[ind]=correct_answers[ind]+(predicted == label).sum().item()
      correctly_predicted_errors[ind]=correctly_predicted_errors[ind]+((predicted == label) & (label>0)).sum().item()
      total_samples[ind]=total_samples[ind]+len(label)
      total_errors[ind]=total_errors[ind] + len(label[label>0])
error_acc = correctly_predicted_errors/total_errors
acc = correct_answers/total_samples

print(f"Test accuracy: {acc}, test error accuracy: {error_acc}")
print(f"Total errors in test dataset: {total_errors}")

arr=np.where(Y_grouped==0, "Нет осложнения", "Осложнение")

"""# Визуализация предсказания"""

save_fig=True
step_number=2

for ind_out, output in enumerate(outputs):
  plt.figure(figsize=(12,3))
  arr=np.where(labels[:,ind_out]==0, "Нет осложнения", "Осложнение")
  plt.scatter(X_grouped[:,-1,0]*max_depth,arr, s=0.5, label='Данные')
  #label=labels[:,ind_out]
  _, predicted = torch.max(output.data, 1)
  pred = predicted.cpu()
      
  plt.scatter(X_grouped[:,-1,0]*max_depth,pred+0.03, s=0.5, label=f'Прогноз на {ind_out+1} шагов')   
  plt.xlabel('Глубина')
    
  plt.legend()
  plt.ylim(top=1.1, bottom=-0.1)
  if (save_fig and ind_out==step_number-1):
    fig_file=file.split('.')[0]
    plt.savefig(directory+'Data/Prediction_vis/'+ fig_file+'_future.png',dpi=600, facecolor='white', bbox_inches='tight')
  
  plt.show()

